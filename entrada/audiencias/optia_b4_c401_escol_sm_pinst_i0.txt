Bueno, . Para mí es un honor estar acá, como les decía, y ser parte de este proceso que nos llena de orgullo a todos como chilenos. Mi presentación se refiere a un tipo de discriminación que se llama discriminación algorítmica. Que [se] da como resultado por el uso de sistemas de inteligencia artificial, la cual se relaciona con el Principio de Igualdad en materia constitucional. 
Mi nombre es Catherine Muñoz, yo soy directora de la ONG OPTIA, o el Observatorio Público para la Transparencia e Inclusión Algorítmica. Constituido por un grupo de profesionales interdisciplinarios con quienes compartimos la preocupación por el impacto social que genera la implementación de sistemas de inteligencia artificial y tecnologías digitales en la sociedad, y en particular frente a grupos vulnerables.  
Bueno, como primer punto, quiero comentarles que existe una narrativa exagerada sobre la inteligencia artificial. Se habla de sistemas autónomos que piensan, aprenden por sí mismos y reemplazan las funciones humanas. Esto se asimila a la "inteligencia artificial general", que es sólo una hipótesis sobre desarrollos, estudios de inteligencias artificiales de orden humano y con capacidad de generalización. Que es la que usualmente vemos en la ciencia ficción, pero que no ha sido desarrollada y se aleja completamente de lo que existe en la actualidad. Existen muchas dudas sobre si este tipo de inteligencia artificial general se irá a desarrollar en algún momento. 
Lo que existe actualmente se llama "inteligencia artificial estrecha", que corresponde a sistemas que resuelven tareas limitadas y específicas, no respondiendo en otro escenario, aunque sea ligeramente diferente. La inteligencia artificial se ha centrado casi exclusivamente - en el mercado, fuera de los laboratorios, fuera de las universidades- en el machine learning o aprendizaje automático, que es parte de esta inteligencia artificial estrecha. Y que es un proceso automatizado de descubrimiento de correlaciones entre variables en un conjunto de datos dentro de un modelo para hacer predicciones y estimaciones de algún resultado determinado con nuevos datos.  
Lo anterior es la definición según el estado del arte, pero para fines regulatorios, es preferible considerar una descripción de sistemas sociotécnicos. Ya que, junto con los componentes técnicos ya referidos, también son esenciales las motivaciones de las personas que participan directamente en el diseño e implementación, así como su contexto social particular. La suma de los factores técnicos y sociales explica los impactos causados por este tipo de tecnología, especialmente aquellos negativos que vulneran los Derechos Humanos; como [es], en este caso, la discriminación algorítmica.
Bueno, la discriminación  directa, en términos generales, que es fácilmente constatable. Por ejemplo, cuando a una persona no la dejan entrar a un restaurante por ser de una nacionalidad determinada. Pero también  indirecta, la cual ocurre cuando una disposición, aparentemente neutra, pone a las personas que comparten una característica protegida en una desventaja desproporcionada en comparación con otras. Este tipo de discriminación es la regla general en materia de discriminación algorítmica. Y aquí no importa el ánimo, sino el resultado.  
Estos son ejemplos de casos de discriminación indirecta algorítmica, que [ocurrieron] en los últimos años, que se ha comprobado, en estos casos, que la inteligencia artificial usada para resolver problemas sociales complejos, reproduce, amplifica y perpetúa las injusticias sociales, afectando desproporcionadamente a grupos vulnerables. Me quiero referir específicamente aquellas discriminaciones producidas por el uso de sistemas de machine learning o que toman decisiones automatizadas o semiautomatizadas que pretenden resolver este tipo de complejidades sociales. Lo anterior es relevante porque este tipo de sistemas actualmente está siendo usado por el Estado de Chile con la finalidad de utilizar su función y prestación de servicios sin ningún control sobre sus consecuencias ni registros sobre sus impactos. 
Bueno ¿Cómo discriminan los algoritmos? Hay una explicación técnica que se divide en sesgos en los modelos y sesgos en los datos. Desde el punto vista técnico en los ojos de los modelos se relacionan con sus límites técnicos, ya que son modelos matemáticos cuantitativos. Por lo que hacen una reducción de datos, no siendo capaces de analizar todas las variables presentes dentro de complejidades sociales. Cuando se habla de predicción, por ejemplo, nos referimos a resultados de correlaciones y no a una predestinación que es sensible a los cambios de contexto. Las variables dentro de las cuales se buscan las correlaciones en materia social se basan en abstracciones, que se traducen en conceptos medibles. Por ejemplo, la delincuencia, la solvencia, la salud, que se consiguen a través de tasas de clicks, códigos postales, cupos de tarjetas de crédito, etcétera; lo que conlleva imprecisiones y riesgo. 
Sobre los sesgos en los datos, bueno, el más característico es [el] sesgo de recopilación, el cual ocurre por inferencias de los mismos sesgos incrustados en los mismos datos. Ya que éstos nunca son neutros, siempre están ligados a historias y a personas; y reducirlos, sin tener en consideración su contexto, lleva a resultados equivocados. 
Ahora [quiero] explicar, desde el punto de vista técnico, [que] este tipo de discriminaciones es limitado porque no hay que olvidar que detrás de estos sistemas hay personas. Hay personas que toman decisiones sobre qué diseñar, cómo y con qué propósito; y también hay un contexto social, donde se reproducen estas dinámicas de poder que les comentaba. Y donde la inteligencia artificial es una herramienta dentro de esta dinámica. 
Bueno, los desafíos del derecho comparado. Lo voy a hablar muy rápidamente. Desde [este] punto de vista, en materia discriminación algorítmica -particularmente discriminación indirecta- es muy difícil encontrar un comparador. Suele ser una tarea muy titánica, ya que las comparaciones son a nivel de grupos y entre personas de circunstancias muy específicas. También existen desafíos en la dificultad probatoria para la víctima y la falta de transparencia tanto de los elementos técnicos como los sociales. 
Y, en Latinoamérica tenemos desafíos adicionales, que son propios de nuestra región. Desde su origen la raza -como construcción social- y la clase están profundamente entrelazadas. Esta unión tiene su origen en dos eventos históricos, ocurridos simultáneamente, la Constitución de América y la creación del capitalismo colonial. La clasificación social de la población colonizada se vio en primera instancia como un fundamento de la dominación, y luego como una parte importante de una nueva economía. Lo anterior dificulta diferenciarlas para efectos de determinar si una persona está siendo discriminada mediante sistemas de inteligencia artificial y en base a qué. 
Otra particularidad que existe en Latinoamérica es que existe una arraigada creencia de superación del racismo, basado en la existencia de un generalizado mestizaje. Sin embargo, las sociedades han mantenido las estructuras jerárquicas que se fundan en el racismo. Esta disonancia denominada "daltonismo racial" se caracteriza por que las personas creen que desigualdades, discriminaciones o perjuicios en el fondo, no son problemas de racismo; sino que los explican por cualquier otro tipo de injusticia, desde otra perspectiva; tales como el mercado, la naturaleza, del azar o la clase. El daltonismo racial puede dificultar la detección de una discriminación algorítmica ya que es probable que una persona no pueda percibir por sí misma que está siendo discriminada y existan sutilezas. Tenemos nuestros propios marcadores racistas; por ejemplo, el tono de piel, el apellido, la estatura, el color del pelo, el colegio donde estudiaste, etcétera. 
¿Cuáles son los desafíos constitucionales desde esta perspectiva? Que vir tanto para términos generales como para los desafíos de nuevas tecnologías. Teniendo presente que los Derechos Humanos no son conceptos estáticos, verdad, deben interpretarse constantemente a la luz de los cambios sociales. El Principio de Igualdad en materia constitucional -me refiero a la Igualdad ante la Ley del artículo 19 número 2- que conlleve implícito una garantía de No Discriminación, debiese ser formulado e interpretado desde una visión colectiva.
Tradicionalmente, la igualdad se entiende como un principio individual, pero desde esta perspectiva no es posible detectar y evaluar injusticias. 
Para determinar que algo es injusto, o sea que algo es discriminador en el fondo, es necesario una visión colectiva y sólo así se puede vislumbrar las desigualdades sociales, raciales y de género. Que son de carácter estructural, en lugar de actos esporádicos, meramente mezquinos o irracionales. 
Por su parte, la Igualdad clásica, entendida como una garantía de No Discriminación, tiene un carácter neutro. No toca las estructuras de injusticia social y mantiene el status quo. Por lo tanto, es preciso entender e interpretar este Principio de Igualdad no sólo desde una visión colectiva, sino como un principio antisubordinado o de No Subordinación. Aquello significa que el propósito principal de este principio va más allá de una garantía de No Discriminación, ya que su finalidad es desmantelar las estructuras sociales que discriminan y excluyen a determinados grupos vulnerables.  
Esta perspectiva de igualdad es significativa a la hora de evaluar, por ejemplo, discriminaciones... 
Ya que clarifica el hecho de que cualquier trato desigual sobre determinados grupos, mediando o no intención, no será tolerado y por lo tanto debe ser sancionado. Puesto que su resultado reproduce y perpetúa las condiciones estructurales que mantienen, en el fondo, la estructura de injusticia social. Y debiese constar en la historia fidedigna de esta nueva Constitución esta forma de interpretación, tanto desde un aspecto colectivo como desde un principio anti subordinado. 
La garantía de no discriminación debe ser entendida también como una visión colectiva, puesto que lo que se afecta con ella, discriminando a una persona en el fondo, es que comparte una característica protegida con un grupo, es afectar a un conjunto de individuos de forma directa, al perpetuar y reforzar discriminaciones de carácter estructural. Asimismo, es menester un concepto de discriminación que pueda hacer frente a nuevos tipos de discriminaciones, como esta en el caso de la discriminación algorítmica. 
Y en ese sentido, por ejemplo, existe un autor que se llama Isaac Collin Hausmann [sic] que ha conceptualizado la discriminación como una acción y actúa en base a una categoría protegida de manera moralmente objetable. En base a una norma ético moral y no simplemente a un comparador o un mecanismo matemático, o medidas matemáticas. Gracias 
 Sobre la primera pregunta, la verdad es que, en general, existen normativas, existen la norma más abierta en la mayor parte de las constituciones. Y remiten, salvo la Constitución norteamericana, que hace una distinción -en verdad- entre normas de rango constitucional y rango legal, pero uno se rige -en el fondo- por los principios supranacionales de los tratados internacionales y debiese continuar como una cláusula abierta. Pero y remitida, en el fondo, la distinción es quizás a la ley, porque de todas maneras todos los grupos protegidos pueden variar, verdad. 
Depende de cada contexto social, se puede -y es lo que un poco comentaba en mi presentación- el contexto social es muy importante. Entonces, los grupos protegidos ahora son unos y más adelante pueden ir variando. Por lo que es importante tener eso presente y también es importante tener [en cuenta] que el marco jurídico comienza -en el fondo- con los tratados internacionales vinculantes en materia de Derechos Humanos. 
Sobre la segunda pregunta. Sobre si existe alguna una Constitución que garantice -en el fondo- este principio desde el punto de vista colectivo. La verdad es que lo que más se aprecia en el derecho comparado, en particular en Estados Unidos, en Europa, es una nueva interpretación de la [14° Enmienda a la Constitución de los] EE.UU. y de las normas a los principios de No Discriminación en Europa. Y lo que se hace es una nueva interpretación del Derecho como estaba -por ejemplo- formalmente escrito desde esta perspectiva. 
Desde esta perspectiva, tanto colectiva, de decir que la única manera de poder evaluar una discriminación estructural, porque el racismo es una discriminación estructural, la discriminación por género es estructural y la clase también es estructural. [Por] "estructural" me refiero a que tiene un origen histórico, que no yo no lo puedo explicar solamente con los rasgos externos, sino que hay toda una construcción social detrás que me permite explicar mejor cómo se produce un tipo de discriminación.
En ese sentido, en Estados Unidos, la Corte Suprema de Estados Unidos y los tribunales de justicia en Europa, en particular el Tribunal de Justicia Europeo. Ellos han elaborado, en el fondo, esta nueva forma de interpretación del Principio de Igualdad, tanto desde el punto de vista colectivo como también como un principio anti subordinador y no sólo como una norma de No Discriminación. 
Esto es importante, porque entenderlo como una garantía de No Discriminación simplemente es una norma neutra, mantiene el status quo. En cambio, entendiéndola como un principio anti subordinador, va más allá de la garantía de la discriminación. Y en el fondo lo que busca es enfrentar y disolver todas estas injusticias estructurales que históricamente excluyen a grupos vulnerables. La inteligencia artificial, en el fondo, tiene una cualidad paradojal, que permite apreciarnos como somos como sociedad. Llegó una tecnología que nos obliga, en el fondo, a vernos como somos como sociedad y lo injusta que es. Y, a partir quizás de ella, poder convertirnos en una mejor sociedad. 
